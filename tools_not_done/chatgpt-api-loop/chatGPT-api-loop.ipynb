{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pimports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (336 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp310-cp310-macosx_11_0_arm64.whl (123 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-macosx_11_0_arm64.whl (34 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.1-cp310-cp310-macosx_11_0_arm64.whl (62 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Installing collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2022.12.7 charset-normalizer-3.1.0 frozenlist-1.3.3 idna-3.4 multidict-6.0.4 openai-0.27.4 requests-2.28.2 tqdm-4.65.0 urllib3-1.26.15 yarl-1.9.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.1 is available.\n",
      "You should consider upgrading via the '/Users/devin/.pyenv/versions/3.10.3/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading pandas-2.0.1-cp310-cp310-macosx_11_0_arm64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/devin/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-1.24.3-cp310-cp310-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/devin/.pyenv/versions/3.10.3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, numpy, pandas\n",
      "Successfully installed numpy-1.24.3 pandas-2.0.1 pytz-2023.3 tzdata-2023.3\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.1 is available.\n",
      "You should consider upgrading via the '/Users/devin/.pyenv/versions/3.10.3/bin/python3.10 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install pandas\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# auths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = \"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\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chatGPT loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_responses(df, model='gpt-3.5-turbo'):\n",
    "    responses = []\n",
    "\n",
    "    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        \n",
    "        file_name = row['File Name']\n",
    "        \n",
    "        # Set up the messages for ChatGPT\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"I am going to supply you a list of boxing matches, such as 'Mike Tyson vs. Evander Holyfield'. I need you to remove all the other stuff in the filename and leave only the 'Fighter vs. Fighter' format. Return only FighterA vs. FighterB. Use their Full names if possible, even if not provided. If you know the last name and nickname, include those. Include a '.' after the vs like vs. Nothing else. Do not end your response with a period. If you cannot do it, leave that cell BLANK.: {file_name}\"}\n",
    "        ]\n",
    "\n",
    "        # Call the OpenAI API with the messages\n",
    "        response = openai.ChatCompletion.create(model=model, messages=messages, max_tokens=3500, temperature=0.5)\n",
    "\n",
    "        # Extract the generated response\n",
    "        generated_text = response.choices[0].message['content'].strip()\n",
    "        responses.append(generated_text)\n",
    "        print(generated_text)\n",
    "\n",
    "        # Add the responses to the DataFrame\n",
    "        df.loc[i, 'Generated Insights'] = generated_text\n",
    "\n",
    "        # Save the updated DataFrame to a temporary CSV file\n",
    "        temp_output_csv_path = 'temp_file_names_with_insights.csv'\n",
    "        df.to_csv(temp_output_csv_path, index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "input_csv_path = 'file_names.csv'\n",
    "df = pd.read_csv(input_csv_path)\n",
    "\n",
    "# Generate responses using ChatGPT and update the DataFrame\n",
    "df_with_insights = generate_responses(df)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "output_csv_path = 'file_names_with_insights.csv'\n",
    "df_with_insights.to_csv(output_csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
