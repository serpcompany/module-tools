{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "csv_file_path = 'input.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Replace NaN values with a placeholder for blanks only if you're sure they represent truly blank cells\n",
    "BLANK_PLACEHOLDER = \"<BLANK>\"  # Define a constant for blank placeholders\n",
    "\n",
    "# Iterate over all columns in the DataFrame\n",
    "for column in df.columns:\n",
    "    df[column].fillna(BLANK_PLACEHOLDER, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df.head()\n",
    "# # df.info()\n",
    "\n",
    "\n",
    "# # Duplicates ----------\n",
    "# print(\"Number of duplicate rows:\", len(df[df.duplicated('account_url', keep=False)]))\n",
    "# df[df.duplicated('account_url', keep=False)].sort_values(['account_url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def consolidate_rows(rows):\n",
    "    \"\"\"Consolidate rows with user input for conflict resolution, handling blank and non-blank values appropriately.\"\"\"\n",
    "    consolidated = rows.iloc[0].copy()  # Start with the first row as the base for consolidation\n",
    "    num_merge_conflicts = sum(len(rows[column].dropna().unique()) > 1 for column in rows.columns)\n",
    "    print(f\"There are {num_merge_conflicts} merge conflicts to resolve: \")\n",
    "    \n",
    "    for column in rows.columns:\n",
    "        # Dropping NaN to consider non-empty values for conflict detection\n",
    "        non_empty_values = rows[column].dropna().unique()\n",
    "        \n",
    "        if len(non_empty_values) == 1:\n",
    "            consolidated[column] = non_empty_values[0]\n",
    "        elif len(non_empty_values) > 1:\n",
    "            print(f\"\\nConflict in '{column}' column with unique values: {non_empty_values}\")\n",
    "            conflict_df = rows[[column]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "            display_df = conflict_df.reset_index().rename(columns={\"index\": \"Choice\"})\n",
    "            display_df['Choice'] += 1  # Adjust choice numbering to start from 1\n",
    "            display(display_df)\n",
    "            \n",
    "            chosen_index = input(f\"Select the row number to keep for {column} (1-{len(conflict_df)}), or type 'exit' to stop: \")\n",
    "            clear_output()  # Clear the output after receiving input\n",
    "            if chosen_index.lower() == 'exit':\n",
    "                print(\"Operation stopped by user. Saving progress...\")\n",
    "                return None\n",
    "            \n",
    "            try:\n",
    "                chosen_index = int(chosen_index) - 1\n",
    "                if 0 <= chosen_index < len(conflict_df):\n",
    "                    consolidated[column] = conflict_df.iloc[chosen_index, 0]\n",
    "                else:\n",
    "                    print(\"Invalid row number. No changes made to this column.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a valid row number or 'exit'.\")\n",
    "                return None\n",
    "        else:\n",
    "            consolidated[column] = np.nan\n",
    "    return consolidated\n",
    "\n",
    "\n",
    "\n",
    "def has_conflict(group):\n",
    "    \"\"\"Check if there is any conflict within the group, ignoring NaN values.\"\"\"\n",
    "    return any(len(group[column].dropna().unique()) > 1 for column in group.columns)\n",
    "\n",
    "def main(csv_file_path):\n",
    "    df = pd.read_csv(csv_file_path, dtype=str)\n",
    "    original_order_df = df.copy()\n",
    "\n",
    "    duplicates = df[df.duplicated('account_url', keep=False)]\n",
    "    \n",
    "    if duplicates.empty:\n",
    "        print(\"No duplicates found.\")\n",
    "        df.to_csv('result.csv', index=False)\n",
    "        return df\n",
    "    \n",
    "    consolidated_list = []\n",
    "    total_conflicts = 0  # Initialize total conflicts count\n",
    "    for account_url, group in duplicates.groupby('account_url'):\n",
    "        if not has_conflict(group):\n",
    "            continue\n",
    "        \n",
    "        total_conflicts += sum(len(group[column].dropna().unique()) > 1 for column in group.columns)\n",
    "        \n",
    "    print(f\"There are {total_conflicts} merge conflicts to resolve: \")\n",
    "    \n",
    "    for account_url, group in duplicates.groupby('account_url'):\n",
    "        if not has_conflict(group):\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing next duplicate group for account_url: {account_url}\")\n",
    "        display(group)\n",
    "        consolidated_row = consolidate_rows(group)\n",
    "        if consolidated_row is None:\n",
    "            print(\"Operation stopped by user. Saving progress...\")\n",
    "            break\n",
    "        consolidated_list.append(consolidated_row)\n",
    "    \n",
    "    if consolidated_list:\n",
    "        consolidated_df = pd.DataFrame(consolidated_list, columns=df.columns)\n",
    "        df = pd.concat([original_order_df, consolidated_df], ignore_index=False)\n",
    "        df = df.drop_duplicates('account_url', keep='last')\n",
    "    \n",
    "    df.sort_index(inplace=True)\n",
    "    df.to_csv('result.csv', index=False)\n",
    "    print(\"Consolidation complete. Results saved to 'result.csv'.\")\n",
    "    return df\n",
    "\n",
    "csv_file_path = 'input.csv'\n",
    "df_processed = main(csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
